{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import cv2  # Importing the OpenCV library for image processing\n",
    "import os  # Importing the OS library for changing the current working directory\n",
    "import h5py  # Importing the h5py library for saving and loading the dataset\n",
    "import pandas as pd  # Importing the pandas library for saving and loading the dataset\n",
    "import numpy as np  # Importing NumPy,which is the fundamental package for scientific computing with Python\n",
    "import tensorflow as tf  # Importing the TensorFlow library for deep learning model training and evaluation\n",
    "import tensorflow_hub as hub  # Importing the TensorFlow Hub library for transfer learning\n",
    "\n",
    "from PIL import Image  # Importing the Image function from PIL\n",
    "\n",
    "# Setting GPU device to run tensorflow\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# Check whether the GPU is available or not\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Speed limit (20km/h)', 1: 'Speed limit (30km/h)', 2: 'Speed limit (50km/h)', 3: 'Speed limit (60km/h)', 4: 'Speed limit (70km/h)', 5: 'Speed limit (80km/h)', 6: 'End of speed limit (80km/h)', 7: 'Speed limit (100km/h)', 8: 'Speed limit (120km/h)', 9: 'No passing', 10: 'No passing veh over 3.5 tons', 11: 'Right-of-way at intersection', 12: 'Priority road', 13: 'Yield', 14: 'Stop', 15: 'No vehicles', 16: 'Veh > 3.5 tons prohibited', 17: 'No entry', 18: 'General caution', 19: 'Dangerous curve left', 20: 'Dangerous curve right', 21: 'Double curve', 22: 'Bumpy road', 23: 'Slippery road', 24: 'Road narrows on the right', 25: 'Road work', 26: 'Traffic signals', 27: 'Pedestrians', 28: 'Children crossing', 29: 'Bicycles crossing', 30: 'Beware of ice/snow', 31: 'Wild animals crossing', 32: 'End speed + passing limits', 33: 'Turn right ahead', 34: 'Turn left ahead', 35: 'Ahead only', 36: 'Go straight or right', 37: 'Go straight or left', 38: 'Keep right', 39: 'Keep left', 40: 'Roundabout mandatory', 41: 'End of no passing', 42: 'End no passing veh > 3.5 tons'}\n"
     ]
    }
   ],
   "source": [
    "trafficSignClasses = {}\n",
    "\n",
    "# Defining the function to load the Traffic Sign Classes from the CSV file\n",
    "data = pd.read_csv(\"trafficSignClasses.csv\")\n",
    "for i in range(len(data)):\n",
    "    trafficSignClasses[data[\"ClassId\"][i]] = data[\"ClassName\"][i]\n",
    "\n",
    "print(trafficSignClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the class for object classification\n",
    "class ObjectClassification:\n",
    "    # Defining the constructor for object classification\n",
    "    def __init__(self):\n",
    "        # Loading the trained model and save it in model\n",
    "\n",
    "        modelUrl = \"https://kaggle.com/models/google/faster-rcnn-inception-resnet-v2/frameworks/TensorFlow1/variations/faster-rcnn-openimages-v4-inception-resnet-v2/versions/1\"\n",
    "        # modelUrl = \"https://kaggle.com/models/google/mobilenet-v2/frameworks/TensorFlow1/variations/openimages-v4-ssd-mobilenet-v2/versions/1\"\n",
    "\n",
    "        # Loading the trained model and save it in model\n",
    "        self.model = hub.load(modelUrl).signatures[\"default\"]\n",
    "\n",
    "    # Defining the function to preprocess the image\n",
    "    def preprocessImage(self, image):\n",
    "        image = cv2.cvtColor(\n",
    "            image, cv2.COLOR_BGR2RGB\n",
    "        )  # Converting the image from BGR to RGB\n",
    "\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)[\n",
    "            tf.newaxis, ...\n",
    "        ]  # Converting the image to float32 data type\n",
    "        return image\n",
    "\n",
    "    # Defining the function to detect objects in the image\n",
    "    def detect(self, image):\n",
    "        image = self.preprocessImage(image)  # Preprocessing the image\n",
    "\n",
    "        # Running the model on the image\n",
    "        detections = self.model(image)\n",
    "\n",
    "        # Extracting the bounding boxes, classes, and scores from the detection\n",
    "        boundingBoxes = detections[\"detection_boxes\"].numpy()\n",
    "        classLabels = detections[\"detection_class_labels\"].numpy()\n",
    "        classNames = detections[\"detection_class_entities\"].numpy()\n",
    "        scores = detections[\"detection_scores\"].numpy()\n",
    "\n",
    "        results = []  # Initializing the results list\n",
    "\n",
    "        # Filtering out the detections with a confidence score less than 0.5\n",
    "        for i in range(len(boundingBoxes)):\n",
    "            if scores[i] > 0.25:\n",
    "                results.append(\n",
    "                    (\n",
    "                        classNames[i].decode(\"utf-8\"),\n",
    "                        classLabels[i],\n",
    "                        scores[i],\n",
    "                        boundingBoxes[i],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the class for traffic sign detection\n",
    "class TrafficSignDetector:\n",
    "    # Defining the constructor for traffic sign detection\n",
    "    def __init__(self):\n",
    "        # Loading the trained model\n",
    "        self.model = tf.keras.models.load_model(\"model/trained_model.keras\")\n",
    "        self.width = 30\n",
    "        self.height = 30\n",
    "        self.channels = 3\n",
    "\n",
    "    # Defining the function to preprocess the image\n",
    "    def preprocessImage(self, image):\n",
    "        values = []  # Initializing the values list\n",
    "        image = Image.fromarray(image, \"RGB\")  # Converting the image to RGB format\n",
    "        image = image.resize((self.width, self.height))  # Resizing the image to 30x30\n",
    "        values.append(np.array(image))  # Appending the image to the image list\n",
    "        finalImage = np.array(values)  # Converting the image list to a NumPy array\n",
    "        finalImage = finalImage / 255  # Normalizing the image\n",
    "        return finalImage\n",
    "\n",
    "    # Defining the function to detect traffic signs in the image\n",
    "    def detect(self, image):\n",
    "        finalImage = self.preprocessImage(image)  # Preprocessing the image\n",
    "\n",
    "        # Running the model on the image\n",
    "        predictions = self.model.predict(finalImage, verbose=0)\n",
    "\n",
    "        # Extracting the class label with the highest probability\n",
    "        trafficLabel = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "        return trafficSignClasses[trafficLabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Defining the main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Creating an instance of the ObjectClassification class\n",
    "    objectClassification = ObjectClassification()\n",
    "\n",
    "    # Creating an instance of the TrafficSignDetector class\n",
    "    trafficSignDetector = TrafficSignDetector()\n",
    "\n",
    "    # Create a VideoCapture object and read from the camera (0 stands for the default camera)\n",
    "    cap = cv2.VideoCapture('./20231124_144733.mp4')\n",
    "    # cap = cv2.VideoCapture(0)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video stream or file\")\n",
    "\n",
    "    # Output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    out = cv2.VideoWriter(\"output-live.avi\", fourcc, fps, (width, height))\n",
    "\n",
    "    # Keep reading from the camera\n",
    "    while True:\n",
    "        # Read a frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check if frame is not empty\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detecting objects in the frame\n",
    "        results = objectClassification.detect(frame)\n",
    "\n",
    "        # Looping over the results\n",
    "        for result in results:\n",
    "            # Extracting the class label, confidence score, and bounding box coordinates\n",
    "            (className, classLabel, score, boundingBox) = result\n",
    "\n",
    "            # Extracting the bounding box coordinates\n",
    "            (startY, startX, endY, endX) = boundingBox\n",
    "\n",
    "            # Convert the bounding box coordinates from relative coordinates to absolute coordinates based on the frame resolution\n",
    "            startX = int(startX * frame.shape[1])\n",
    "            startY = int(startY * frame.shape[0])\n",
    "            endX = int(endX * frame.shape[1])\n",
    "            endY = int(endY * frame.shape[0])\n",
    "\n",
    "            # Check if the detected object is a traffic sign\n",
    "            if classLabel == 96 or classLabel == 183:\n",
    "                # Drawing the bounding box on the frame along with the class label and confidence score\n",
    "                cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "\n",
    "                # Region of interest (ROI) extraction\n",
    "                roi = frame[startY:endY, startX:endX]\n",
    "\n",
    "                # Detecting the traffic sign in the ROI\n",
    "                trafficSign = trafficSignDetector.detect(roi)\n",
    "\n",
    "                # Displaying the class label and confidence score\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    trafficSign + \": \" + str(round(score * 100, 2)) + \"%\",\n",
    "                    (startX, startY - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.45,\n",
    "                    (0, 0, 255),\n",
    "                )\n",
    "\n",
    "        # Writing the frame into the output video\n",
    "        out.write(frame)\n",
    "\n",
    "        # Displaying the frame\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "        # Press Q on keyboard to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nvidia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
